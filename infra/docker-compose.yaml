services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 10


  kafka:
      image: confluentinc/cp-kafka:7.6.1
      depends_on:
        zookeeper:
          condition: service_healthy
      ports:
        - "9092:9092"    # container internal
        - "29092:29092"  # host-accessible
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
        KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
        KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      volumes:
        - ./kafka:/data/kafka 
      healthcheck:
        test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
        interval: 10s
        timeout: 5s
        retries: 10


  spark:
    image: apache/spark:3.5.1-java17  # FIXED TAG
    environment:
      SPARK_MODE: driver
    volumes:
      - ../streaming:/app         # adjust relative path to your project root
      - ../storage:/data
    depends_on:
      kafka:
        condition: service_healthy
    # Example submit:
    # docker compose exec spark spark-submit --packages io.delta:delta-spark_2.12:3.2.0 /app/spark_app/main.py

  grafana:
    image: grafana/grafana:latest
    ports: ["3000:3000"]
    volumes:
      - ./grafana:/etc/grafana/provisioning

  mongodb:
    image: mongo:6
    ports: ["27017:27017"]
    volumes:
      - mongo_data:/data/db

volumes:
  mongo_data:
